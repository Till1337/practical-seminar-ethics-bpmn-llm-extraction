# Training Pipeline for Ethical Analysis

This pipeline is designed to analyze business process models for ethical considerations using Large Language Models (LLMs). It automates the process of extracting process descriptions, applying various prompting techniques for ethical analysis, and evaluating the results using an LLM-as-judge approach.

## Project Structure

The `Training-Pipeline` directory is organized as follows:

-   **`analysis/`**: Contains the core logic for the ethical analysis.
    -   `ethics_analyzer.py`: Defines the main `EthicsAnalyzer` class that orchestrates the analysis by applying different prompting techniques.
    -   `prompting_techniques.py`: Implements the various advanced prompting strategies used for the ethical analysis (e.g., Zero-Shot, Few-Shot, Chain of Verification).

-   **`common/`**: Includes utility scripts and shared functionality used across the pipeline.
    -   `llm_api.py`: A wrapper for making API calls to the Language Model (e.g., Google Gemini).
    -   `process_extraction.py`: Functions to extract structured process descriptions and steps from `.gv` files.
    -   `utils.py`: Helper functions for formatting data and processing results.

-   **`data/`**: Stores the core data definitions used in the analysis.
    -   `ethics_values.py`: Defines the set of ethical values that the analysis is based on.

-   **`combined_dataset/`**: This directory contains all the business process models used for analysis, stored in `.gv` format.
    -   **Standard Dataset**: The primary dataset is composed of 15 folders, each representing a unique business process (e.g., `account_payable_process`, `loan_application_process`, ...) from the MaD Dataset. These are used for the main analysis with the standard 12B model.
    -   **Pro Dataset**: The `combined_dataset/Gemma-2.5Pro_dataset/` folder contains a specialized dataset intended for analysis with the "Pro" model.

-   **`results/`**: All output files from the analysis and evaluation are stored here.
    -   `results/gemma3-results/`: Contains the analysis and evaluation results generated by the Gemma-3 model.
    -   `results/pro-results/`: Contains the analysis and evaluation results generated by the Gemma-2.5-Pro model.

-   **Root Directory Scripts**:
    -   `ethics_analyzer_loop.py`: The main script to run the ethical analysis loop over the dataset.
    -   `llm-as-judge.py`: The script to evaluate the analysis results using an LLM.
    -   `rerun_missing_entries.py`: A utility script to re-process any files or techniques that were missed in the initial run.

## How to Run the Pipeline

Follow these steps to run the complete training and evaluation pipeline.

### 1. Installation

First, ensure you have all the necessary Python packages installed by running:

```bash
pip install -r requirements.txt
```

### 2. Running the Analysis

The pipeline consists of two main steps:

#### Step 1: Ethical Analysis Loop

This script iterates through the process models in the `combined_dataset` directory, applies a suite of prompting techniques to analyze ethical values, and saves the output.

To run the analysis loop:

```bash
python ethics_analyzer_loop.py
```
un
This will generate / edit an `ethics_analysis.csv` file in the `results/` directory which can be stopped and continued later on.

#### Step 2: LLM-as-Judge Evaluation

After the initial analysis is complete, this script uses a "judge" LLM to evaluate the quality of the generated ethical analysis based on criteria like comprehensiveness, accuracy, and relevance.

To run the evaluation:

```bash
python llm-as-judge.py
```

This reads the `ethics_analysis.csv` and produces an `llm_judge_evaluation.csv` file in the `results/` directory. The script can be at any time stopped and continued later on.

### 3. Handling Missing Entries (Optional)

If the analysis script (`ethics_analyzer_loop.py`) was interrupted or failed to process certain files or techniques, you can run a script to find and process only the missing entries without re-running the entire dataset.

To rerun missing entries:

```bash
python rerun_missing_entries.py
```

You can also target specific prompting techniques that you want to rerun. For example, to only process missing entries for `tree_of_thoughts` and `chain_of_verification`:

```bash
python rerun_missing_entries.py --techniques tree_of_thoughts chain_of_verification
```